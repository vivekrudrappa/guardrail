<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> 
  <title>Astra AI Guardrail Prototype</title>
  <style>
    h2 {
        color: #232f3e;
        border-bottom: 3px solid #ff9900;
        padding-bottom: 10px;
        margin-top: 40px;
    }
    /* new added styles */
    .subtitle {
        text-align: center;
        margin-bottom: 40px;
        font-style: italic;
    }
    .grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
        gap: 20px;
        margin-top: 20px;
    }
    
    .card {
        border: 1px solid #e1e8ed;
        border-radius: 8px;
        padding: 20px;
        background: #fff;
        transition: all 0.3s ease;
        position: relative;
    }
    
    .card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        border-color: #ff9900;
    }
    
    .card h3 {
        color: #232f3e;
        margin: 0 0 12px 0;
        font-size: 1.1em;
        display: flex;
        align-items: center;
        gap: 10px;
    }
    
    .card p {
        color: #555;
        margin: 0 0 10px 0;
        font-size: 0.95em;
    }
    
    .card .actions {
        font-size: 0.85em;
        color: #666;
        font-weight: 500;
    }
    
    .badge {
        display: inline-block;
        padding: 4px 8px;
        border-radius: 12px;
        font-size: 0.7em;
        font-weight: bold;
        text-transform: uppercase;
        margin-left: auto;
    }
    
    .badge.content-filter { background: #e3f2fd; color: #1976d2; }
    .badge.pii { background: #f3e5f5; color: #7b1fa2; }
    .badge.custom { background: #e8f5e8; color: #388e3c; }
    .badge.prompt { background: #fff3e0; color: #f57c00; }
    .badge.contextual { background: #fce4ec; color: #c2185b; }
    
    .icon {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        display: inline-block;
    }
    
    .icon.hate { background: #ffebee; border: 2px solid #f44336; }
    .icon.violence { background: #fff3e0; border: 2px solid #ff9800; }
    .icon.sexual { background: #fce4ec; border: 2px solid #e91e63; }
    .icon.misconduct { background: #f3e5f5; border: 2px solid #9c27b0; }
    .icon.pii { background: #e3f2fd; border: 2px solid #2196f3; }
    .icon.custom { background: #e8f5e8; border: 2px solid #4caf50; }
    .icon.prompt { background: #fff8e1; border: 2px solid #ffc107; }
    .icon.contextual { background: #e0f2f1; border: 2px solid #009688; }
    
    .note {
        background: #f0f8ff;
        border-left: 4px solid #2196f3;
        padding: 15px;
        margin: 20px 0;
        border-radius: 4px;
    }
    
    .strength-indicator {
        font-size: 0.8em;
        margin-top: 8px;
        padding: 4px 8px;
        background: #f5f5f5;
        border-radius: 4px;
        display: inline-block;
    }
    /* new added styles end */
    body {
      font-family: "Segoe UI", Roboto, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #f8f9fa;
      color: #333;
      line-height: 1.6;
    }
    header {
      background: linear-gradient(135deg, #2c3e50, #4ca1af);
      color: white;
      padding: 30px 20px;
      text-align: center;
    }
    header h1 {
      margin: 0;
      font-size: 2rem;
    }
    header p {
      font-size: 1.1rem;
      margin-top: 10px;
      max-width: 700px;
      margin-left: auto;
      margin-right: auto;
    }
    main {
      padding: 20px;
      max-width: 1000px;
      margin: auto;
    }
    section {
      margin-bottom: 30px;
      background: white;
      padding: 20px;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    section h2 {
      color: #2c3e50;
      margin-bottom: 10px;
    }

    label {
      font-weight: bold;
      margin-top: 15px;
      display: block;
    }
    select, button {
      margin: 8px 0;
      padding: 12px;
      width: 100%;
      font-size: 1rem;
      border: 1px solid #ccc;
      border-radius: 8px;
      box-sizing: border-box;
    }
    textarea {
      background: #f8f9fa;
      margin: 10px 0;
      padding: 12px;
      width: 100%;
      max-width: 800px;
      height: 120px;
      font-size: 14px;
      resize: vertical; /* allows user to expand */
    }
    button {
      background-color: #4ca1af;
      color: white;
      border: none;
      cursor: pointer;
      transition: background 0.3s;
    }
    button:hover {
      background-color: #357f8a;
    }
    #result {
      margin-top: 15px;
      padding: 15px;
      border-radius: 10px;
      background: #f4f6f7;
      border: 1px solid #ddd;
      min-height: 120px;
      white-space: pre-wrap;
      font-size: 0.95rem;
      overflow-x: auto;
    }
    footer {
      text-align: center;
      padding: 20px;
      font-size: 0.9rem;
      color: #555;
      background: #f1f1f1;
      margin-top: 40px;
    }
    .config-panel {
      margin-top: 20px;
      padding: 15px;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .config-panel label {
      display: block;
      margin: 8px 0;
    }
    pre {
      background: #f8f9fa;
      padding: 1rem;
      border-radius: 0.5rem;
      max-height: 300px;
      overflow: auto;
    }

    /* Floating Chat Button old one
    #chatButton {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #4ca1af;
      color: white;
      padding: 15px;
      border-radius: 50%;
      cursor: pointer;
      font-size: 20px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.2);
      z-index: 1000;
    }
    #chatButton:hover {
      background-color: #357f8a;
    } */
    /* Floating Chat Button */
    #chatButton {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #4ca1af;
      color: white;
      padding: 15px;
      border-radius: 50%;
      cursor: pointer;
      font-size: 20px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.2);
      z-index: 1000;
      transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    #chatButton:hover {
      background-color: #357f8a;
      transform: translateY(-4px); /* lifts button upward */
      box-shadow: 0 8px 12px rgba(0,0,0,0.3); /* stronger shadow */
    }
  
    /* Chat Popup */
    #chatPopup {
      display: none;
      position: fixed;
      bottom: 80px;
      right: 20px;
      width: 350px;
      max-height: 500px;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
      display: None;
      flex-direction: column;
      overflow: hidden;
      z-index: 1000;
      font-family: Arial, sans-serif;
    }
  
    .chat-header {
      background: #4ca1af;
      color: white;
      padding: 10px;
      display: flex;
      justify-content: space-between;
      font-weight: bold;
    }
    .chat-header button {
      background: #4ca1af;       /* give it a background */
      border: none;
      font-size: 16px;
      cursor: pointer;
      color: white;
      width: 40px;               /* fixed width */
      height: 40px;              /* fixed height */
      border-radius: 50%;        /* make it circular */
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;            /* prevent shrinking */
    }
    .chat-header button:hover {
      background-color: #357f8a;
    }
  
    .chat-body {
      flex: 1;
      padding: 10px;
      overflow-y: auto;
      background: #f9f9f9;
    }
    /*
    .chat-input {
      display: flex;
      border-top: 1px solid #ddd;
    }
    */
    .chat-input input {
      flex: 1;
      height: 20px;
      padding: 10px;
      border: none;
      outline: none;
    }
  
    .chat-input button {
      background: #4ca1af;       /* give it a background */
      border: none;
      font-size: 16px;
      cursor: pointer;
      color: white;
      width: 40px;               /* fixed width */
      height: 40px;              /* fixed height */
      border-radius: 50%;        /* make it circular */
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;            /* prevent shrinking */
    }
    .chat-input button:hover {
      background-color: #357f8a;
    }
  
    .message {
      margin: 8px 0;
      padding: 8px 12px;
      border-radius: 18px;
      max-width: 75%;
      line-height: 1.4;
      clear: both;
    }
  
    .user-message {
      background: #DCF8C6;
      float: right;
      text-align: right;
    }
  
    .bot-message {
      background: #eee;
      float: left;
      text-align: left;
    }
    .chat-input {
      display: flex;
      align-items: flex-end;
      gap: 8px;
      padding: 10px;
      border-top: 1px solid #ddd;
      background: #f9f9f9;
    }
    
    .chat-input textarea {
      flex: 1;
      min-height: 40px;   /* 2 lines */
      max-height: 120px;  /* won’t grow too big */
      padding: 8px;
      border: 1px solid #ccc;
      border-radius: 15px;
      resize: none;       /* prevent manual resize */
      line-height: 1.4;
      font-size: 14px;
      overflow-y: auto;
    }
    /*
    .chat-input button {
      background: none;
      border: none;
      font-size: 18px;
      cursor: pointer;
      color: #007bff;
    }
    */
    /* Chat modal old styling end */

  </style>
</head>
<body>
  <header>
    <h1>Astra AI Guardrail Prototype</h1>
    <p class="subtitle">Feather light guardrail solutions at your door steps</p>
    <p>
      AI Guardrails help ensure that AI systems behave safely, responsibly, and in alignment with 
      business and ethical standards. This prototype demonstrates real-time input/output scanning 
      to detect risks such as sensitive data leaks, bias, or harmful content.
    </p>
  </header>

  <main>
    <h1>Why AI Guardrails Matter</h1>
    <p class="subtitle">Understanding the Critical Importance of AI Safety and Compliance</p>
    <p>
      As AI adoption accelerates across industries, ensuring trust, compliance, and responsible AI use becomes critical. 
      Guardrails act as safety nets, reducing risks of misinformation, sensitive data exposure, 
      reputational harm, and regulatory non-compliance.
    </p>

    <section>
      <h2>The Stakes Are Higher Than Ever</h2>
      <div class="grid">
        <div class="card">
          <h3>73% of Executives</h3>
          <p>cite AI risk management as their top priority for 2025, according to recent enterprise surveys.</p>
          <div class="actions">Source: Enterprise AI Risk Management Survey 2024</div>
        </div>
        <div class="card">
          <h3>$6.2M Average Cost</h3>
          <p>of AI-related data breaches, significantly higher than traditional data security incidents.</p>
          <div class="actions">Source: IBM Cost of Data Breach Report 2024</div>
        </div>
        <div class="card">
          <h3>89% of Consumers</h3>
          <p>want AI transparency and expect companies to be accountable for AI-driven decisions.</p>
          <div class="actions">Source: Consumer Trust in AI Report 2024</div>
        </div>
      </div>
    </section>

    <section>
      <h2>Critical Risks Without Proper Guardrails</h2>
      <div class="grid">
        <div class="card">
          <h3>🛡️ Data Privacy Violations</h3>
          <p>Accidental exposure of sensitive customer information through AI model outputs or training data leakage.</p>
        </div>
        <div class="card">
          <h3>⚖️ Regulatory Non-Compliance</h3>
          <p>Failure to meet GDPR, HIPAA, SOX, or emerging AI governance requirements leading to hefty fines.</p>
        </div>
        <div class="card">
          <h3>📈 Reputational Damage</h3>
          <p>Public relations disasters from biased AI outputs or inappropriate content generation.</p>
        </div>
        <div class="card">
          <h3>🎯 Biased Decision Making</h3>
          <p>Discriminatory outcomes in hiring, lending, or customer service leading to lawsuits.</p>
        </div>
        <div class="card">
          <h3>💰 Financial Losses</h3>
          <p>Direct costs from regulatory fines, legal settlements, and lost customer trust.</p>
        </div>
        <div class="card">
          <h3>🚨 Security Breaches</h3>
          <p>Prompt injection attacks and adversarial inputs compromising system integrity.</p>
        </div>
      </div>
    </section>

    <section>
      <h2>Real-World Industry Impact</h2>
      
      <div class="grid">
        <div class="card">
          <h3>🏥 Healthcare</h3>
          <p><strong>Risk Without Guardrails:</strong> An AI diagnostic tool recommends treatment based on biased training data, leading to misdiagnosis for underrepresented patient groups. Patient data is inadvertently exposed through AI model outputs.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Bias detection prevents discriminatory recommendations, data masking protects patient privacy, and compliance checks ensure HIPAA adherence. Clinical validation gates ensure safe deployment.
          </div>
        </div>

        <div class="card">
          <h3>🏦 Financial Services</h3>
          <p><strong>Risk Without Guardrails:</strong> AI loan approval system exhibits racial bias, leading to regulatory fines and discrimination lawsuits. Customer financial data leaks through model inference attacks.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Fairness metrics prevent discriminatory lending, differential privacy protects customer data, and explainability features ensure regulatory compliance with fair lending laws.
          </div>
        </div>

        <div class="card">
          <h3>🏭 Manufacturing</h3>
          <p><strong>Risk Without Guardrails:</strong> AI-controlled production line makes dangerous adjustments due to adversarial inputs, causing equipment damage and safety hazards. Proprietary manufacturing data is exposed.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Input validation detects anomalies, safety constraints prevent dangerous operations, and data governance protects intellectual property while maintaining operational efficiency.
          </div>
        </div>

        <div class="card">
          <h3>🛒 E-commerce & Retail</h3>
          <p><strong>Risk Without Guardrails:</strong> AI recommendation engine promotes harmful products, chatbots share competitor pricing, and dynamic pricing algorithms enable price discrimination leading to customer backlash.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Content filtering prevents harmful recommendations, information barriers protect competitive data, and fairness controls ensure ethical pricing while maximizing customer satisfaction.
          </div>
        </div>

        <div class="card">
          <h3>📚 Education</h3>
          <p><strong>Risk Without Guardrails:</strong> AI tutoring system provides incorrect information, assessment tools exhibit bias against certain student groups, and student data is misused for commercial purposes.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Fact-checking prevents misinformation, bias detection ensures fair assessments, and privacy controls protect student data in compliance with FERPA and COPPA regulations.
          </div>
        </div>

        <div class="card">
          <h3>🚗 Automotive</h3>
          <p><strong>Risk Without Guardrails:</strong> Autonomous vehicle AI makes unsafe decisions in edge cases, predictive maintenance systems provide false alerts causing unnecessary costs, and vehicle data is compromised.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Safety validation prevents dangerous maneuvers, uncertainty quantification improves maintenance predictions, and secure data handling protects driver privacy and vehicle security.
          </div>
        </div>

        <div class="card">
          <h3>⚖️ Legal Services</h3>
          <p><strong>Risk Without Guardrails:</strong> AI legal research tools cite non-existent cases ("hallucinations"), contract analysis misses critical clauses, and confidential client information is exposed through model outputs.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Citation verification prevents false legal precedents, accuracy thresholds ensure reliable analysis, and attorney-client privilege protection maintains confidentiality and professional standards.
          </div>
        </div>

        <div class="card">
          <h3>📺 Media & Entertainment</h3>
          <p><strong>Risk Without Guardrails:</strong> AI content generation creates deepfakes for misinformation, recommendation algorithms promote extremist content, and copyrighted material is inappropriately used in generated content.</p>
          <div class="note">
            <strong>✅ With AI Guardrails:</strong> Authenticity verification prevents deepfake abuse, content moderation filters harmful material, and copyright protection ensures legal compliance while fostering creative innovation.
          </div>
        </div>
      </div>
    </section>

    <section>
      <h2>The Business Case for AI Guardrails</h2>
      <div class="grid">
        <div class="card">
          <h3>🔒 Trust & Compliance</h3>
          <p>Build customer confidence and meet regulatory requirements from day one, avoiding costly retrofitting and compliance gaps.</p>
        </div>
        <div class="card">
          <h3>⚡ Faster Deployment</h3>
          <p>Accelerate AI project timelines with built-in safety measures that prevent delays from risk assessments and security reviews.</p>
        </div>
        <div class="card">
          <h3>💡 Innovation Enablement</h3>
          <p>Enable bold AI initiatives by providing the safety foundation that allows teams to innovate with confidence.</p>
        </div>
        <div class="card">
          <h3>📊 Measurable ROI</h3>
          <p>Demonstrate clear return on investment through reduced incidents, faster compliance, and increased customer trust metrics.</p>
        </div>
      </div>
    </section>

    <h1>Supported Guardrail Types & Capabilities</h1>

    <!-- OLD VIEW DETAILS section>
      <h2>Types of Guardrails</h2>
      <div class="grid">
        <div class="card"><h3>PII & Sensitive Info</h3><p>Detects personal or confidential data such as SSNs, emails, or financial info.</p></div>
        <div class="card"><h3>Ban Codes/Strings</h3><p>Blocks restricted words, codes, or phrases from being processed.</p></div>
        <div class="card"><h3>Gibberish</h3><p>Prevents meaningless or non-constructive input that could pollute results.</p></div>
        <div class="card"><h3>Invisible Text</h3><p>Identifies hidden characters or obfuscated input that may be malicious.</p></div>
        <div class="card"><h3>Language Detection</h3><p>Ensures input is in allowed languages for compliance and relevance.</p></div>
        <div class="card"><h3>Prompt Injection</h3><p>Stops adversarial prompts trying to bypass AI rules.</p></div>
        <div class="card"><h3>Regex & Custom Rules</h3><p>Flexible pattern matching to block business-specific sensitive data.</p></div>
        <div class="card"><h3>Secrets/Keys</h3><p>Detects accidental leakage of API keys, tokens, or credentials.</p></div>
        <div class="card"><h3>Inappropriate Sentiment</h3><p>Flags hostile, offensive, or aggressive tone.</p></div>
        <div class="card"><h3>Toxicity & Harm</h3><p>Detects hate speech, violence, or harmful content.</p></div>
        <div class="card"><h3>Bias & Fairness</h3><p>Checks for biased language or discriminatory output.</p></div>
      </div>
  </section-->

    <div class="note">
        <strong>Note:</strong> This list reflects the actual capabilities available as of Aug 2025. Each guardrail can be configured with different strength levels and actions (NONE, BLOCK, MASK).
    </div>
  
    <section>
        <h2>Content Filters - Harmful Categories</h2>
        <div class="grid">
            <div class="card">
                <h3><span class="icon hate"></span>Hate Speech Filter <span class="badge content-filter">Content Policy</span></h3>
                <p>Detects and filters hate speech, discrimination, and prejudiced language targeting individuals or groups.</p>
                <div class="actions">Actions: NONE | BLOCK</div>
                <div class="strength-indicator">Configurable Strength: LOW | MEDIUM | HIGH</div>
            </div>
            
            <div class="card">
                <h3><span class="icon violence"></span>Violence Filter <span class="badge content-filter">Content Policy</span></h3>
                <p>Identifies violent content, threats, or descriptions of harmful physical actions.</p>
                <div class="actions">Actions: NONE | BLOCK</div>
                <div class="strength-indicator">Configurable Strength: LOW | MEDIUM | HIGH</div>
            </div>
            
            <div class="card">
                <h3><span class="icon sexual"></span>Sexual Content Filter <span class="badge content-filter">Content Policy</span></h3>
                <p>Blocks inappropriate sexual content, explicit material, or adult themes.</p>
                <div class="actions">Actions: NONE | BLOCK</div>
                <div class="strength-indicator">Configurable Strength: LOW | MEDIUM | HIGH</div>
            </div>
            
            <div class="card">
                <h3><span class="icon misconduct"></span>Misconduct Filter <span class="badge content-filter">Content Policy</span></h3>
                <p>Prevents content that promotes illegal activities, fraud, or unethical behavior.</p>
                <div class="actions">Actions: NONE | BLOCK</div>
                <div class="strength-indicator">Configurable Strength: LOW | MEDIUM | HIGH</div>
            </div>
            
            <div class="card">
                <h3><span class="icon violence"></span>Insults Filter <span class="badge content-filter">Content Policy</span></h3>
                <p>Detects personal attacks, insults, and offensive language directed at individuals.</p>
                <div class="actions">Actions: NONE | BLOCK</div>
                <div class="strength-indicator">Configurable Strength: LOW | MEDIUM | HIGH</div>
            </div>
        </div>
    </section>
  
    <section>
        <h2>PII & Sensitive Information Protection</h2>
        <div class="grid">
            <div class="card">
                <h3><span class="icon pii"></span>PII Detection (31 Types) <span class="badge pii">Sensitive Info</span></h3>
                <p>Comprehensive detection of personally identifiable information including names, emails, phone numbers, SSNs, addresses, credit cards, and more.</p>
                <div class="actions">Actions: BLOCK | MASK | DETECT (no action)</div>
                <div class="strength-indicator">Supports all major PII categories with individual configuration</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Custom Regex Patterns <span class="badge custom">Custom Rules</span></h3>
                <p>Define custom regular expressions to detect business-specific sensitive data patterns.</p>
                <div class="actions">Actions: BLOCK | MASK | DETECT</div>
                <div class="strength-indicator">Fully customizable pattern matching</div>
            </div>
        </div>
    </section>
  
    <section>
        <h2>Word & Topic Filtering</h2>
        <div class="grid">
            <div class="card">
                <h3><span class="icon custom"></span>Profanity Filter <span class="badge custom">Word Filters</span></h3>
                <p>Built-in profanity detection with support for custom word and phrase lists.</p>
                <div class="actions">Actions: BLOCK | MASK</div>
                <div class="strength-indicator">Customizable with your own word lists</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Denied Topics <span class="badge custom">Topic Control</span></h3>
                <p>Block specific topics or subject areas from being discussed or generated.</p>
                <div class="actions">Actions: BLOCK</div>
                <div class="strength-indicator">Topic-level filtering with configurable tiers</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Custom Word Filters <span class="badge custom">Word Lists</span></h3>
                <p>Add your own custom words, phrases, or terms to be filtered or blocked.</p>
                <div class="actions">Actions: BLOCK | MASK</div>
                <div class="strength-indicator">Fully customizable vocabulary control</div>
            </div>
        </div>
    </section>
  
    <section>
        <h2>Advanced Protection</h2>
        <div class="grid">
            <div class="card">
                <h3><span class="icon prompt"></span>Prompt Attack Protection <span class="badge prompt">Prompt Safety</span></h3>
                <p>Detects and blocks prompt injection attacks, jailbreaking attempts, and adversarial inputs designed to bypass AI safety measures.</p>
                <div class="actions">Actions: BLOCK</div>
                <div class="strength-indicator">Advanced prompt attack detection</div>
            </div>
            
            <div class="card">
                <h3><span class="icon contextual"></span>Contextual Grounding Checks <span class="badge contextual">Contextual</span></h3>
                <p>Ensures responses are grounded in provided context and checks for relevance to the input query.</p>
                <div class="actions">Grounding & Relevance Validation</div>
                <div class="strength-indicator">Context adherence and relevance scoring</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Automated Reasoning Check <span class="badge contextual">AI Reasoning</span></h3>
                <p>Validates the logical reasoning and consistency of AI-generated responses.</p>
                <div class="actions">Reasoning validation and consistency checks</div>
                <div class="strength-indicator">Automated logical validation</div>
            </div>
        </div>
    </section>
  
    <section>
        <h2>Configuration Options</h2>
        <div class="grid">
            <div class="card">
                <h3><span class="icon custom"></span>Content Filter Tiers <span class="badge custom">Configuration</span></h3>
                <p>Configurable sensitivity levels for all content filters with LOW, MEDIUM, and HIGH strength settings.</p>
                <div class="actions">Granular control over filter sensitivity</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Blocked Messaging <span class="badge custom">User Experience</span></h3>
                <p>Customize the messages shown to users when content is blocked or filtered.</p>
                <div class="actions">Personalized user-facing messaging</div>
            </div>
            
            <div class="card">
                <h3><span class="icon custom"></span>Separate Input/Output Control <span class="badge custom">Directional</span></h3>
                <p>Configure different guardrail behaviors for user inputs (prompts) versus AI outputs (responses).</p>
                <div class="actions">Independent prompt and response filtering</div>
            </div>
        </div>
    </section>

    <section>
      <h1>Demo Configs for AI Guardrails</h1>
      <p>
        Choose the options below. Depending on your configuration, your input and/or LLM output will be filtered 
        by Guardrail services before or after going to the LLM (OpenAI). 
      </p>
      <label for="apikey">🔑 Enter Open API Key </label>
      <input type="password" id="apikey" placeholder="sk-..." style="width:100%; padding:10px;" />
      <label for="model">⚙️ Select Open AI GPT Model</label>
      <select id="model">
        <option value="gpt-4o-mini">gpt-4o-mini (fast, cheap)</option>
        <option value="gpt-4o">gpt-4o</option>
        <option value="gpt-3.5-turbo" selected>gpt-3.5-turbo</option>
      </select>

      <div class="config-panel">
        <h3>Configuration</h3>
        <label><input type="checkbox" id="inputFilter"> Enable Input Guardrails</label>
        <label><input type="checkbox" id="outputFilter"> Enable Output Guardrails</label>
      </div>
    </section>

      <section>
        <h2>How This Demo Works?</h2>
        <p>
          Enter text below, toggle/select options above, and click <b>Check</b>. 
          The system sends your input to a guardrail service based on input/output filter selection, which evaluates it against 
          multiple scanning rules both things going into LLM and response coming out of LLM. Shows the results in real-time.
        </p>
  
        <label for="userInput">Enter text to check:</label>
        <textarea id="userInput" placeholder="Type something here... like mentioning person name, date of birth, address"></textarea><br>
  
        <button onclick="checkText()">Check</button>
  
        <!-- <pre id="result">Awaiting input...</pre> -->
      </section>

      <section>
        <h3>Results:</h3>
        <!-- Tabbed Results -->
        <ul class="nav nav-tabs" id="resultTabs" role="tablist">
          <li class="nav-item" role="presentation">
            <button class="nav-link active" id="user-tab" data-bs-toggle="tab" data-bs-target="#user" type="button" role="tab">User View</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="dev-tab" data-bs-toggle="tab" data-bs-target="#developer" type="button" role="tab">Developer View</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="dash-tab" data-bs-toggle="tab" data-bs-target="#dashboard" type="button" role="tab">Dashboard</button>
          </li>
        </ul>
  
        
        <div class="tab-content mt-3">
          <!-- User View -->
          <div class="tab-pane fade show active" id="user" role="tabpanel">
            <div class="mb-3">
              <label class="fw-bold">Original Input:</label>
              <textarea id="originalText" class="form-control" readonly></textarea>
            </div>
            <div class="mb-3">
              <label class="fw-bold">Input Filter Applied:</label> <span id="inputFilterStatus"></span>
              <textarea id="filteredInput" class="form-control" readonly></textarea>
            </div>
            <div class="mb-3">
              <label class="fw-bold">Output Filter Applied:</label> <span id="outputFilterStatus"></span>
              <textarea id="finalOutput" class="form-control" readonly></textarea>
            </div>
          </div>
          
          <!-- Developer View -->
          <div class="tab-pane fade" id="developer" role="tabpanel">
            <label class="fw-bold">Raw JSON Response</label>
            <textarea id="jsonOutput" class="form-control" readonly></textarea>
          </div>
    
          <!-- Dashboard View -->
          <div class="tab-pane fade" id="dashboard" role="tabpanel">
            <div class="row">
              <div class="col-md-6">
                <canvas id="piiChart"></canvas>
              </div>
              <div class="col-md-6">
                <ul class="list-group" id="summaryList"></ul>
              </div>
            </div>
          </div>
        <!-- Tab View closure -->
        </div>
       <!-- Results section closure -->
      </section>
    <!-- AI prototype with config section closure -->
    </section>
  </main>

  <!-- Floating Chat Button -->
  <div id="chatButton" onclick="toggleChatPopup()">💬</div>
  
  <!-- Chat Popup -->
  <div id="chatPopup">
    <div class="chat-header">
      <span>Astrabot</span>
      <button onclick="toggleChatPopup()">✖</button>
    </div>
    <div class="chat-body" id="chatMessages"></div>
    <div class="chat-input">
      <textarea id="chatInput" placeholder="Type your message to send it to LLM..."></textarea>
      <button onclick="sendChat()">➤</button>
    </div>

    <!--div class="chat-input">
      <input type="text" id="chatInput" placeholder="Type your message to send it to LLM..." />
      <button onclick="sendChat()">Send</button>
    </div-->
  </div>

  <footer>
    © 2025 Astra NextGen Technologies, LLC. | Building Trustworthy AI
  </footer>

<script>
  const endpoints = {
    aws: "https://9r2j9zq0yd.execute-api.us-east-2.amazonaws.com/prod/aiGuardrailPrototype",
    openai: "https://api.openai.com/v1/chat/completions"
  };

  async function checkText() {
    // Step 0: Clear previous results before starting
    // document.getElementById("resultText").value = "";      // User View output
    // document.getElementById("jsonOutput").value = "";      // Developer View JSON
    // document.getElementById("dashboardContent").innerHTML = ""; // Dashboard content

    const inputText = document.getElementById('userInput').value;
    const resultTabDiv = document.getElementById('originalText');
    const key = document.getElementById("apikey").value;
    const model = document.getElementById("model").value;

    resultTabDiv.textContent = "Processing...";

    if (!inputText) return;

    let processedInput = inputText;

    const useInputFilter = document.getElementById("inputFilter").checked;
    const useOutputFilter = document.getElementById("outputFilter").checked;

    try {
      // Step 1: Apply input guardrails
      let inputData = {};
      if (useInputFilter) {
        resultTabDiv.textContent = "Applying Input Guardrails...";
        const payload = {
          text: processedInput,
          filter_type: "INPUT"
        };
        const resp = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });
        if (!resp.ok) {
          throw new Error(`HTTP error! Status: ${resp.status}`);
        }
        inputData = await resp.json();
        processedInput = inputData.guardrail_filtered_text || processedInput;
      }

      // Step 2: Call OpenAI
      let llmResponse = "No response from LLM.";
      resultTabDiv.textContent = "Sending info to Generative AI LLM...";
      if (!key) {
        resultTabDiv.textContent = "Please enter the Open AI LLM API Key (password) above key box to continue...";
        return;
      }
      const respLLM = await fetch(endpoints.openai, {
        method: "POST",
        headers: { 
          "Content-Type": "application/json",
          "Authorization": `Bearer ${key}`
        },
        body: JSON.stringify({
          model,
          messages: [{ role: "user", content: processedInput }],
          temperature: 0.5,
          max_tokens: 512
        })
      });

      if (!respLLM.ok) {
        throw new Error(`OpenAI error! Status: ${respLLM.status}`);
      }

      const dataLLM = await respLLM.json();
      llmResponse = dataLLM.choices?.[0]?.message?.content || llmResponse;

      // Step 3: Apply output guardrails
      let outputData = {};
      if (useOutputFilter) {
        resultTabDiv.textContent = "Applying Output Guardrails...";
        const payload = {
          text: llmResponse,
          filter_type: "OUTPUT"
        };
        const resp = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });
        if (!resp.ok) {
          throw new Error(`HTTP error! Status: ${resp.status}`);
        }
        outputData = await resp.json();
        llmResponse = outputData.guardrail_filtered_text || llmResponse;
      }

      // --- User View ---
      document.getElementById("originalText").value = inputText;
      document.getElementById("inputFilterStatus").innerText = useInputFilter ? "Yes Input Filter Applied" : "No Input Filter NOT Applied";
      document.getElementById("filteredInput").value = processedInput ? processedInput : "N/A";
      document.getElementById("outputFilterStatus").innerText = useOutputFilter ? "Yes Ouput Filter Applied" : "No Output Filter NOT Applied";
      document.getElementById("finalOutput").value = llmResponse;

      // --- Developer View ---
      const mergedData = { inputData, outputData };
      document.getElementById("jsonOutput").value = JSON.stringify(mergedData, null, 2);

      // --- Simulated Backend Results (replace with actual AWS capability to plot charts for below via AWS API call) ---
      const simulatedResponse = {
        piiDetected: 3,
        sensitiveDetected: 1,
        awsResponse: {
          piiEntities: ["Phone", "Email", "Name"],
          toxicity: "low",
          sentiment: "negative"
        }
      };
        // --- Dashboard ---
      const ctx = document.getElementById('piiChart');
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: ['PII Detected', 'Sensitive Data'],
          datasets: [{
            label: 'Counts',
            data: [simulatedResponse.piiDetected, simulatedResponse.sensitiveDetected]
          }]
        }
      });
    
      const summary = document.getElementById("summaryList");
      summary.innerHTML = `
        <li class="list-group-item">PII Detected: ${simulatedResponse.piiDetected}</li>
        <li class="list-group-item">Sensitive Data: ${simulatedResponse.sensitiveDetected}</li>
        <li class="list-group-item">Toxicity: ${simulatedResponse.awsResponse.toxicity}</li>
        <li class="list-group-item">Sentiment: ${simulatedResponse.awsResponse.sentiment}</li>
      `;

    // checkText function try block
    } catch (error) {
      console.error("Error calling API via UI:", error);
      resultTabDiv.textContent = "❌ Error: " + error.message;
    }
  // checkText function closure
  }
</script>

<script>
  
  function toggleChatPopup() {
    const popup = document.getElementById("chatPopup");
    popup.style.display = popup.style.display === "flex" ? "none" : "flex";
  }

  async function sendChat() {
    const inputField = document.getElementById("chatInput");
    const message = inputField.value.trim();
    const useInputFilter = document.getElementById("inputFilter").checked;
    const useOutputFilter = document.getElementById("outputFilter").checked;
    if (!message) return;

    // Show user message
    appendMessage(message, "user-message");
    inputField.value = "";

    // Step 1: Input Guardrail
    let blocked = false;
    let guardrailReason = "";

    if (useInputFilter) {
      appendMessage("Analyzing with input Guardrail...", "bot-message");
      try {
        const payload = {
          text: message,
          filter_type: "INPUT",   // can also be "OUTPUT"
        };
        const response = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });
        if (!response.ok) {
          throw new Error(`HTTP error from input guardrail in chat client! Status: ${response.status}`);
        }
        const data = await response.json();
  
        if (data.pii.detected) {
          blocked = true;
          guardrailReason = data.guardrail_filtered_text || "Sensitive information detected.";
        }
      } catch (err) {
        console.error("Guardrail check failed:", err);
      }
      if (blocked) {
        appendMessage("⚠️ " + guardrailReason + " Please re-enter without sensitive info which shows as redacted.", "bot-message");
        return;
      }
    } // useInputFilter condition closing



    // Step 2: Call OpenAI
    appendMessage("Sending user input to LLM...", "bot-message");
    const key = document.getElementById("apikey").value;
    const model = document.getElementById("model").value;
    if (!key) {
      appendMessage("Please enter the Open AI LLM API Key (password)", "bot-message");
      return;
    }
    
    let llmText = "Default no response";
    try {
      const llmResponse = await fetch(endpoints.openai, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${key}`
        },
        body: JSON.stringify({
          model: model,
          messages: [{ role: "user", content: message }]
        })
      });
      const llmData = await llmResponse.json();

      llmText = llmData?.choices?.[0]?.message?.content || "No response";
    } catch (error) {
      appendMessage("❌ Error calling LLM.", "bot-message" + error);
    }

    // Step 3: Output Guardrail
    let finalText = llmText;
    if (useOutputFilter) {
      try {
        appendMessage("Updating LLM response if needed with output Guardrail before showing to the user...", "bot-message");

        const payload = {
          text: llmText,
          filter_type: "OUTPUT",   // can also be "OUTPUT"
          checkOutput: true
        };
        const outResponse = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });

        const outData = await outResponse.json();
        if (outData?.guardrail_filtered_text) {
          finalText = outData.guardrail_filtered_text;
        }
      } catch (err) {
        console.error("Output guardrail failed in chat client:", err);
      }
    }

    appendMessage(finalText, "bot-message");
    // Replace "Processing or progress status..." with real response
    // const chatBody = document.getElementById("chatMessages");
    // chatBody.lastChild.textContent = finalText;
  } // sendChat function closure

  function appendMessage(text, className) {
    const chatBody = document.getElementById("chatMessages");
    const msg = document.createElement("div");
    msg.className = "message " + className;
    msg.textContent = text;
    chatBody.appendChild(msg);
    chatBody.scrollTop = chatBody.scrollHeight;
  }
</script>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
