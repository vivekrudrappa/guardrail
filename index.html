<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> 
  <title>Astra AI Guardrail Prototype</title>
  <style>
    body {
      font-family: "Segoe UI", Roboto, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #f8f9fa;
      color: #333;
      line-height: 1.6;
    }
    header {
      background: linear-gradient(135deg, #2c3e50, #4ca1af);
      color: white;
      padding: 30px 20px;
      text-align: center;
    }
    header h1 {
      margin: 0;
      font-size: 2rem;
    }
    header p {
      font-size: 1.1rem;
      margin-top: 10px;
      max-width: 700px;
      margin-left: auto;
      margin-right: auto;
    }
    main {
      padding: 20px;
      max-width: 1000px;
      margin: auto;
    }
    section {
      margin-bottom: 30px;
      background: white;
      padding: 20px;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    section h2 {
      color: #2c3e50;
      margin-bottom: 10px;
    }
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 15px;
    }
    .card {
      background: #fdfdfd;
      border: 1px solid #e0e0e0;
      border-radius: 10px;
      padding: 15px;
      box-shadow: 0 3px 6px rgba(0,0,0,0.1);
    }
    .card h3 {
      margin-top: 0;
      color: #4ca1af;
      font-size: 1.1rem;
    }
    label {
      font-weight: bold;
      margin-top: 15px;
      display: block;
    }
    select, button {
      margin: 8px 0;
      padding: 12px;
      width: 100%;
      font-size: 1rem;
      border: 1px solid #ccc;
      border-radius: 8px;
      box-sizing: border-box;
    }
    textarea {
      background: #f8f9fa;
      margin: 10px 0;
      padding: 12px;
      width: 100%;
      max-width: 800px;
      height: 120px;
      font-size: 14px;
      resize: vertical; /* allows user to expand */
    }
    button {
      background-color: #4ca1af;
      color: white;
      border: none;
      cursor: pointer;
      transition: background 0.3s;
    }
    button:hover {
      background-color: #357f8a;
    }
    #result {
      margin-top: 15px;
      padding: 15px;
      border-radius: 10px;
      background: #f4f6f7;
      border: 1px solid #ddd;
      min-height: 120px;
      white-space: pre-wrap;
      font-size: 0.95rem;
      overflow-x: auto;
    }
    footer {
      text-align: center;
      padding: 20px;
      font-size: 0.9rem;
      color: #555;
      background: #f1f1f1;
      margin-top: 40px;
    }
    .config-panel {
      margin-top: 20px;
      padding: 15px;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .config-panel label {
      display: block;
      margin: 8px 0;
    }
    pre {
      background: #f8f9fa;
      padding: 1rem;
      border-radius: 0.5rem;
      max-height: 300px;
      overflow: auto;
    }

    /* Floating Chat Button */
    #chatButton {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #4ca1af;
      color: white;
      padding: 15px;
      border-radius: 50%;
      cursor: pointer;
      font-size: 20px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.2);
      z-index: 1000;
    }
  
    /* Chat Popup */
    #chatPopup {
      display: none;
      position: fixed;
      bottom: 80px;
      right: 20px;
      width: 350px;
      max-height: 500px;
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
      display: flex;
      flex-direction: column;
      overflow: hidden;
      z-index: 1000;
      font-family: Arial, sans-serif;
    }
  
    .chat-header {
      background: #4ca1af;
      color: white;
      padding: 10px;
      display: flex;
      justify-content: space-between;
      font-weight: bold;
    }
  
    .chat-body {
      flex: 1;
      padding: 10px;
      overflow-y: auto;
      background: #f9f9f9;
    }
  
    .chat-input {
      display: flex;
      border-top: 1px solid #ddd;
    }
  
    .chat-input input {
      flex: 1;
      height: 20px;
      padding: 10px;
      border: none;
      outline: none;
    }
  
    .chat-input button {
      background: #4ca1af;
      border: none;
      color: white;
      padding: 10px 15px;
      cursor: pointer;
    }
  
    .message {
      margin: 8px 0;
      padding: 8px 12px;
      border-radius: 18px;
      max-width: 75%;
      line-height: 1.4;
      clear: both;
    }
  
    .user-message {
      background: #DCF8C6;
      float: right;
      text-align: right;
    }
  
    .bot-message {
      background: #eee;
      float: left;
      text-align: left;
    }
    /* Chat modal old styling end */

  </style>
</head>
<body>
  <header>
    <h1>AI Guardrail Prototype</h1>
    <p>
      AI Guardrails help ensure that AI systems behave safely, responsibly, and in alignment with 
      business and ethical standards. This prototype demonstrates real-time input/output scanning 
      to detect risks such as sensitive data leaks, bias, or harmful content.
    </p>
  </header>

  <main>
    <section>
      <h2>Why AI Guardrails Matter</h2>
      <p>
        As AI adoption accelerates, ensuring trust, compliance, and responsible AI use becomes critical. 
        Guardrails act as safety nets, reducing risks of misinformation, sensitive data exposure, 
        reputational harm, and regulatory non-compliance.
      </p>
    </section>

    <section>
      <h2>Types of Guardrails</h2>
      <div class="grid">
        <div class="card"><h3>PII & Sensitive Info</h3><p>Detects personal or confidential data such as SSNs, emails, or financial info.</p></div>
        <div class="card"><h3>Ban Codes/Strings</h3><p>Blocks restricted words, codes, or phrases from being processed.</p></div>
        <div class="card"><h3>Gibberish</h3><p>Prevents meaningless or non-constructive input that could pollute results.</p></div>
        <div class="card"><h3>Invisible Text</h3><p>Identifies hidden characters or obfuscated input that may be malicious.</p></div>
        <div class="card"><h3>Language Detection</h3><p>Ensures input is in allowed languages for compliance and relevance.</p></div>
        <div class="card"><h3>Prompt Injection</h3><p>Stops adversarial prompts trying to bypass AI rules.</p></div>
        <div class="card"><h3>Regex & Custom Rules</h3><p>Flexible pattern matching to block business-specific sensitive data.</p></div>
        <div class="card"><h3>Secrets/Keys</h3><p>Detects accidental leakage of API keys, tokens, or credentials.</p></div>
        <div class="card"><h3>Inappropriate Sentiment</h3><p>Flags hostile, offensive, or aggressive tone.</p></div>
        <div class="card"><h3>Toxicity & Harm</h3><p>Detects hate speech, violence, or harmful content.</p></div>
        <div class="card"><h3>Bias & Fairness</h3><p>Checks for biased language or discriminatory output.</p></div>
      </div>
    </section>

    <section>
      <h2>Options for AI Guardrails</h2>
      <p>
        Choose the options below. Depending on your configuration, your input and/or LLM output will be filtered 
        by AWS Guardrail services before or after going to the LLM (OpenAI). 
      </p>
      <label for="apikey">üîë Enter Open API Key </label>
      <input type="password" id="apikey" placeholder="sk-..." style="width:100%; padding:10px;" />
      <label for="model">‚öôÔ∏è Select Open AI GPT Model</label>
      <select id="model">
        <option value="gpt-4o-mini">gpt-4o-mini (fast, cheap)</option>
        <option value="gpt-4o">gpt-4o</option>
        <option value="gpt-3.5-turbo" selected>gpt-3.5-turbo</option>
      </select>

      <div class="config-panel">
        <h3>Configuration</h3>
        <label><input type="checkbox" id="inputFilter"> Enable Input Guardrails</label>
        <label><input type="checkbox" id="outputFilter"> Enable Output Guardrails</label>
      </div>

      <section>
        <h2>How This Demo Works</h2>
        <p>
          Enter text below, toggle/select options above, and click <b>Check</b>. 
          The system sends your input to a guardrail service based on input/output filter selection, which evaluates it against 
          multiple scanning rules both things going into LLM and response coming out of LLM. Shows the results in real-time.
        </p>
  
        <label for="userInput">Enter text to check:</label>
        <textarea id="userInput" placeholder="Type something here... like mentioning person name, date of birth, address"></textarea><br>
  
        <button onclick="checkText()">Check</button>
  
        <!-- <pre id="result">Awaiting input...</pre> -->
      </section>

      <section>
        <h3>Results:</h3>
        <!-- Tabbed Results -->
        <ul class="nav nav-tabs" id="resultTabs" role="tablist">
          <li class="nav-item" role="presentation">
            <button class="nav-link active" id="user-tab" data-bs-toggle="tab" data-bs-target="#user" type="button" role="tab">User View</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="dev-tab" data-bs-toggle="tab" data-bs-target="#developer" type="button" role="tab">Developer View</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="dash-tab" data-bs-toggle="tab" data-bs-target="#dashboard" type="button" role="tab">Dashboard</button>
          </li>
        </ul>
  
        
        <div class="tab-content mt-3">
          <!-- User View -->
          <div class="tab-pane fade show active" id="user" role="tabpanel">
            <div class="mb-3">
              <label class="fw-bold">Original Input:</label>
              <textarea id="originalText" class="form-control" readonly></textarea>
            </div>
            <div class="mb-3">
              <label class="fw-bold">Input Filter Applied:</label> <span id="inputFilterStatus"></span>
              <textarea id="filteredInput" class="form-control" readonly></textarea>
            </div>
            <div class="mb-3">
              <label class="fw-bold">Output Filter Applied:</label> <span id="outputFilterStatus"></span>
              <textarea id="finalOutput" class="form-control" readonly></textarea>
            </div>
          </div>
          
          <!-- Developer View -->
          <div class="tab-pane fade" id="developer" role="tabpanel">
            <label class="fw-bold">Raw JSON Response</label>
            <textarea id="jsonOutput" class="form-control" readonly></textarea>
          </div>
    
          <!-- Dashboard View -->
          <div class="tab-pane fade" id="dashboard" role="tabpanel">
            <div class="row">
              <div class="col-md-6">
                <canvas id="piiChart"></canvas>
              </div>
              <div class="col-md-6">
                <ul class="list-group" id="summaryList"></ul>
              </div>
            </div>
          </div>
        <!-- Tab View closure -->
        </div>
       <!-- Results section closure -->
      </section>
    <!-- AI prototype with config section closure -->
    </section>
  </main>

  <!-- Floating Chat Button -->
  <div id="chatButton" onclick="toggleChatPopup()">üí¨</div>
  
  <!-- Chat Popup -->
  <div id="chatPopup">
    <div class="chat-header">
      <span>Chatbot</span>
      <button onclick="toggleChatPopup()">‚úñ</button>
    </div>
    <div class="chat-body" id="chatMessages"></div>
    <div class="chat-input">
      <input type="text" id="chatInput" placeholder="Type your message to send it to LLM..." />
      <button onclick="sendChat()">Send</button>
    </div>
  </div>

  <footer>
    ¬© 2025 Astra NextGen Technologies, LLC. | Building Trustworthy AI
  </footer>

<script>
  const endpoints = {
    aws: "https://9r2j9zq0yd.execute-api.us-east-2.amazonaws.com/prod/aiGuardrailPrototype",
    openai: "https://api.openai.com/v1/chat/completions"
  };

  async function checkText() {
    // Step 0: Clear previous results before starting
    // document.getElementById("resultText").value = "";      // User View output
    // document.getElementById("jsonOutput").value = "";      // Developer View JSON
    // document.getElementById("dashboardContent").innerHTML = ""; // Dashboard content

    const inputText = document.getElementById('userInput').value;
    const resultTabDiv = document.getElementById('originalText');
    const key = document.getElementById("apikey").value;
    const model = document.getElementById("model").value;

    resultTabDiv.textContent = "Processing...";

    if (!inputText) return;

    let processedInput = inputText;

    const useInputFilter = document.getElementById("inputFilter").checked;
    const useOutputFilter = document.getElementById("outputFilter").checked;

    try {
      // Step 1: Apply input guardrails
      let inputData = {};
      if (useInputFilter) {
        resultTabDiv.textContent = "Applying Input Guardrails...";
        const resp = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: processedInput })
        });
        if (!resp.ok) {
          throw new Error(`HTTP error! Status: ${resp.status}`);
        }
        inputData = await resp.json();
        processedInput = inputData.masked_text || processedInput;
      }

      // Step 2: Call OpenAI
      let llmResponse = "No response from LLM.";
      resultTabDiv.textContent = "Sending info to Generative AI LLM...";
      const respLLM = await fetch(endpoints.openai, {
        method: "POST",
        headers: { 
          "Content-Type": "application/json",
          "Authorization": `Bearer ${key}`
        },
        body: JSON.stringify({
          model,
          messages: [{ role: "user", content: processedInput }],
          temperature: 0.5,
          max_tokens: 512
        })
      });

      if (!respLLM.ok) {
        throw new Error(`OpenAI error! Status: ${respLLM.status}`);
      }

      const dataLLM = await respLLM.json();
      llmResponse = dataLLM.choices?.[0]?.message?.content || llmResponse;

      // Step 3: Apply output guardrails
      let outputData = {};
      if (useOutputFilter) {
        resultTabDiv.textContent = "Applying Output Guardrails...";
        const resp = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: llmResponse })
        });
        if (!resp.ok) {
          throw new Error(`HTTP error! Status: ${resp.status}`);
        }
        outputData = await resp.json();
        llmResponse = outputData.masked_text || llmResponse;
      }

      // --- User View ---
      document.getElementById("originalText").value = inputText;
      document.getElementById("inputFilterStatus").innerText = useInputFilter ? "Yes" : "No";
      document.getElementById("filteredInput").value = processedInput ? processedInput : "N/A";
      document.getElementById("outputFilterStatus").innerText = useOutputFilter ? "Yes" : "No";
      document.getElementById("finalOutput").value = llmResponse;

      // --- Developer View ---
      const mergedData = { inputData, outputData };
      document.getElementById("jsonOutput").value = JSON.stringify(mergedData, null, 2);

      // --- Simulated Backend Results (replace with actual AWS capability to plot charts for below via AWS API call) ---
      const simulatedResponse = {
        piiDetected: 3,
        sensitiveDetected: 1,
        awsResponse: {
          piiEntities: ["Phone", "Email", "Name"],
          toxicity: "low",
          sentiment: "negative"
        }
      };
        // --- Dashboard ---
      const ctx = document.getElementById('piiChart');
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: ['PII Detected', 'Sensitive Data'],
          datasets: [{
            label: 'Counts',
            data: [simulatedResponse.piiDetected, simulatedResponse.sensitiveDetected]
          }]
        }
      });
    
      const summary = document.getElementById("summaryList");
      summary.innerHTML = `
        <li class="list-group-item">PII Detected: ${simulatedResponse.piiDetected}</li>
        <li class="list-group-item">Sensitive Data: ${simulatedResponse.sensitiveDetected}</li>
        <li class="list-group-item">Toxicity: ${simulatedResponse.awsResponse.toxicity}</li>
        <li class="list-group-item">Sentiment: ${simulatedResponse.awsResponse.sentiment}</li>
      `;

    // checkText function try block
    } catch (error) {
      console.error("Error calling API via UI:", error);
      resultTabDiv.textContent = "‚ùå Error: " + error.message;
    }
  // checkText function closure
  }
</script>

<script>
  
  function toggleChatPopup() {
    const popup = document.getElementById("chatPopup");
    popup.style.display = popup.style.display === "flex" ? "none" : "flex";
  }

  async function sendChat() {
    const inputField = document.getElementById("chatInput");
    const message = inputField.value.trim();
    const useInputFilter = document.getElementById("inputFilter").checked;
    const useOutputFilter = document.getElementById("outputFilter").checked;
    if (!message) return;

    // Show user message
    appendMessage(message, "user-message");
    inputField.value = "";

    // Step 1: Input Guardrail
    let blocked = false;
    let guardrailReason = "";

    if (useInputFilter) {
      appendMessage("Analyzing with input Guardrail...", "bot-message");
      try {
        const response = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: message })
        });
        if (!response.ok) {
          throw new Error(`HTTP error from input guardrail in chat client! Status: ${response.status}`);
        }
        const data = await response.json();
  
        if (data.pii.detected) {
          blocked = true;
          guardrailReason = data.redacted_text || "Sensitive information detected.";
        }
      } catch (err) {
        console.error("Guardrail check failed:", err);
      }
      if (blocked) {
        appendMessage("‚ö†Ô∏è " + guardrailReason + " Please re-enter without sensitive info which shows as redacted.", "bot-message");
        return;
      }
    } // useInputFilter condition closing



    // Step 2: Call OpenAI
    appendMessage("Sending user input to LLM...", "bot-message");
    const key = document.getElementById("apikey").value;
    const model = document.getElementById("model").value;
    if (!key) {
      appendMessage("Please enter the Open AI LLM API Key (password)", "bot-message");
      return;
    }
    
    let llmText = "Default no response";
    try {
      const llmResponse = await fetch(endpoints.openai, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${key}`
        },
        body: JSON.stringify({
          model: model,
          messages: [{ role: "user", content: message }]
        })
      });
      const llmData = await llmResponse.json();

      llmText = llmData?.choices?.[0]?.message?.content || "No response";
    } catch (error) {
      appendMessage("‚ùå Error calling LLM.", "bot-message" + error);
    }

    // Step 3: Output Guardrail
    let finalText = llmText;
    if (useOutputFilter) {
      try {
        appendMessage("Updating LLM response if needed with output Guardrail before showing to the user...", "bot-message");
        const outResponse = await fetch(endpoints.aws, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: llmText, checkOutput: true })
        });
        const outData = await outResponse.json();
        if (outData?.redacted) {
          finalText = outData.redacted;
        }
      } catch (err) {
        console.error("Output guardrail failed in chat client:", err);
      }
    }

    appendMessage(finalText, "bot-message");
    // Replace "Processing or progress status..." with real response
    // const chatBody = document.getElementById("chatMessages");
    // chatBody.lastChild.textContent = finalText;
  } // sendChat function closure

  function appendMessage(text, className) {
    const chatBody = document.getElementById("chatMessages");
    const msg = document.createElement("div");
    msg.className = "message " + className;
    msg.textContent = text;
    chatBody.appendChild(msg);
    chatBody.scrollTop = chatBody.scrollHeight;
  }
</script>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
